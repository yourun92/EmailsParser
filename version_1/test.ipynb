{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e3acd34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json: 426kB [00:00, 4.25MB/s]                    \n",
      "2025-05-12 16:39:34 INFO: Downloaded file to C:\\Users\\iurii_enix\\stanza_resources\\resources.json\n",
      "2025-05-12 16:39:34 INFO: Downloading these customized packages for language: ru (Russian)...\n",
      "========================================\n",
      "| Processor       | Package            |\n",
      "----------------------------------------\n",
      "| tokenize        | syntagrus          |\n",
      "| pos             | syntagrus_charlm   |\n",
      "| lemma           | syntagrus_nocharlm |\n",
      "| pretrain        | conll17            |\n",
      "| forward_charlm  | newswiki           |\n",
      "| backward_charlm | newswiki           |\n",
      "========================================\n",
      "\n",
      "2025-05-12 16:39:34 INFO: File exists: C:\\Users\\iurii_enix\\stanza_resources\\ru\\tokenize\\syntagrus.pt\n",
      "2025-05-12 16:39:34 INFO: File exists: C:\\Users\\iurii_enix\\stanza_resources\\ru\\pos\\syntagrus_charlm.pt\n",
      "2025-05-12 16:39:34 INFO: File exists: C:\\Users\\iurii_enix\\stanza_resources\\ru\\lemma\\syntagrus_nocharlm.pt\n",
      "2025-05-12 16:39:34 INFO: File exists: C:\\Users\\iurii_enix\\stanza_resources\\ru\\pretrain\\conll17.pt\n",
      "2025-05-12 16:39:34 INFO: File exists: C:\\Users\\iurii_enix\\stanza_resources\\ru\\forward_charlm\\newswiki.pt\n",
      "2025-05-12 16:39:34 INFO: File exists: C:\\Users\\iurii_enix\\stanza_resources\\ru\\backward_charlm\\newswiki.pt\n",
      "2025-05-12 16:39:34 INFO: Finished downloading models and saved to C:\\Users\\iurii_enix\\stanza_resources\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "\n",
    "stanza.download('ru', processors='tokenize,pos,lemma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "68bdbfd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 17:10:03 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json: 426kB [00:00, 3.79MB/s]                    \n",
      "2025-05-12 17:10:04 INFO: Downloaded file to C:\\Users\\iurii_enix\\stanza_resources\\resources.json\n",
      "2025-05-12 17:10:04 INFO: Loading these models for language: ru (Russian):\n",
      "==================================\n",
      "| Processor | Package            |\n",
      "----------------------------------\n",
      "| tokenize  | syntagrus          |\n",
      "| pos       | syntagrus_charlm   |\n",
      "| lemma     | syntagrus_nocharlm |\n",
      "==================================\n",
      "\n",
      "2025-05-12 17:10:04 INFO: Using device: cpu\n",
      "2025-05-12 17:10:04 INFO: Loading: tokenize\n",
      "2025-05-12 17:10:04 INFO: Loading: pos\n",
      "2025-05-12 17:10:08 INFO: Loading: lemma\n",
      "2025-05-12 17:10:12 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "nlp = stanza.Pipeline('ru', processors='tokenize,pos,lemma', use_gpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d3ce1386",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = [\n",
    "    \"гидрошпонка\", \"фиксатор арматуры\", \"бетон\", \"арматура\", \"эмульсол\",\n",
    "    \"опалубка\", \"опалубочные\", \"БДК\", \"балка\", \"замок\", \"ригель\",\n",
    "    \"бентонитовый\", \"гернитовый\", \"бентонит\", \"гернит\"\n",
    "]\n",
    "\n",
    "\n",
    "def lemmatize_phrase(phrase):\n",
    "    doc = nlp(phrase.lower())\n",
    "    return \" \".join([word.lemma for sent in doc.sentences for word in sent.words])\n",
    "\n",
    "# Леммы ключевых фраз\n",
    "lemmatized_keywords = [lemmatize_phrase(k) for k in keywords]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d7d639f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['гидрошпонка',\n",
       " 'фиксатор арматура',\n",
       " 'бетон',\n",
       " 'арматура',\n",
       " 'эмульсол',\n",
       " 'опалубка',\n",
       " 'опалубочный',\n",
       " 'бдк',\n",
       " 'балк',\n",
       " 'замок',\n",
       " 'ригель',\n",
       " 'бентонитовый',\n",
       " 'гернитовый',\n",
       " 'бентонит',\n",
       " 'гернит']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatized_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a2499763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       "  [\n",
       "    {\n",
       "      \"id\": 1,\n",
       "      \"text\": \"пароль\",\n",
       "      \"lemma\": \"пароль\",\n",
       "      \"upos\": \"NOUN\",\n",
       "      \"feats\": \"Animacy=Inan|Case=Nom|Gender=Masc|Number=Sing\",\n",
       "      \"start_char\": 0,\n",
       "      \"end_char\": 6,\n",
       "      \"misc\": \"SpaceAfter=No\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": 2,\n",
       "      \"text\": \",\",\n",
       "      \"lemma\": \",\",\n",
       "      \"upos\": \"PUNCT\",\n",
       "      \"start_char\": 6,\n",
       "      \"end_char\": 7,\n",
       "      \"misc\": \"SpaceAfter=No\"\n",
       "    }\n",
       "  ]\n",
       "]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp('пароль,')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e24cbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "body = '''From: Кирилл Одиноков <kirill@enix.ru>\n",
    "Subject: Re: Api wotstat\n",
    "Body: отзывы, характеристики, как, что, сертификат, паспорт, производитель,\n",
    "ростов, воронеж, условия хранения, сериал, фильм, смотреть, в хорошем\n",
    "качестве, онлайн, применение, в чебоксарах, сп, калькулятор, снип, в\n",
    "красноярске, в краснодаре, букв, леруа, сканворд, краснодар,\n",
    "екатеринбург, требования, в частном доме, фото, видео, youtube, инструкция\n",
    "\n",
    "24.03.2025 8:54, Останин Юрий Андреевич пишет:\n",
    "--\n",
    "Email Signature\n",
    "Logo <https://www.enix.ru>      Logo\n",
    "Одиноков Кирилл\n",
    "\n",
    "+ 7 (915) 404 00 60 | +7 (978) 313 96 25\n",
    "kirill@enix.ru| www.enix.ru <http://www.enix.ru>\n",
    "Офис: г. Москва, Большой Саввинский переулок дом 9 стр. 2, Бухгалтерские\n",
    "документы: buh@enix.ru\n",
    "Facebook icon <https://vk.com/enyx_ru> LinkedIn icon\n",
    "<https://ru-ru.facebook.com/enyx.ru/>\n",
    "\n",
    "Banner <https://enix.ru>'''\n",
    "\n",
    "\n",
    "doc = nlp(body.lower())\n",
    "string = [word.lemma for sent in nlp('условии хранений').sentences for word in sent.words][0]\n",
    "lemmas_in_text = \" \".join([word.lemma for sent in doc.sentences for word in sent.words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8247ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "75398d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse(word='торговая компания', tag=OpencorporaTag('NOUN,inan,femn sing,nomn'), normal_form='торговая компания', score=1.0, methods_stack=((FakeDictionary(), 'торговая компания', 41, 0), (KnownSuffixAnalyzer(min_word_length=4, score_multiplier=0.5), 'пания')))\n",
      "торговая компания\n",
      "торговая компании\n",
      "торговая компании\n",
      "торговая компанию\n",
      "торговая компанией\n",
      "торговая компаниею\n",
      "торговая компании\n",
      "торговая компании\n",
      "торговая компаний\n",
      "торговая компаниям\n",
      "торговая компании\n",
      "торговая компаниями\n",
      "торговая компаниях\n"
     ]
    }
   ],
   "source": [
    "import pymorphy3\n",
    "\n",
    "morph = pymorphy3.MorphAnalyzer()\n",
    "word = morph.parse('торговая компания')[0]\n",
    "\n",
    "print(word)\n",
    "# Получить все формы слова\n",
    "for form in word.lexeme:\n",
    "    print(form.word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "90bcc1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy3\n",
    "from groups import sales_company\n",
    "import pandas as pd\n",
    "\n",
    "morph = pymorphy3.MorphAnalyzer()\n",
    "\n",
    "phrases = sales_company\n",
    "\n",
    "cases = ['nomn', 'gent', 'datv', 'accs', 'ablt', 'loct']\n",
    "numbers = ['sing', 'plur']\n",
    "data = []\n",
    "for phrase in phrases:\n",
    "    phrs = phrase.split()\n",
    "    parses = [morph.parse(p)[0] for p in phrs]\n",
    "    pos_tags = [p.tag.POS for p in parses]\n",
    "\n",
    "    if len(phrs) != 1 and 'NOUN' in pos_tags:\n",
    "        noun = parses[pos_tags.index('NOUN')]\n",
    "\n",
    "        for number in numbers:\n",
    "            for case in cases:\n",
    "                new_words = []\n",
    "                for p in parses:\n",
    "                    # Для существительного — склоняем с учетом рода\n",
    "                    if p.tag.POS == 'NOUN':\n",
    "                        inflected = p.inflect({case, number})\n",
    "                    # Для прилагательного — с согласованием по роду и числу\n",
    "                    elif p.tag.POS == 'ADJF':\n",
    "                        if number == 'sing':\n",
    "                            inflected = p.inflect({case, number, noun.tag.gender})\n",
    "                        else:\n",
    "                            inflected = p.inflect({case, number})\n",
    "                    else:\n",
    "                        inflected = p  # оставляем без изменений, если не умеем склонять\n",
    "\n",
    "                    new_words.append(inflected.word if inflected else p.word)\n",
    "\n",
    "                data.append(' '.join(new_words))\n",
    "\n",
    "    else:\n",
    "        data.extend([f.word for f in morph.parse(phrase)[0].lexeme])\n",
    "\n",
    "pd.DataFrame(data).drop_duplicates().to_excel('some.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7182e4d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['+7 (495) 105-97-55',\n",
       " '+7-910-480-24-89',\n",
       " '+7 (495) 155 68 46',\n",
       " '+79639488295',\n",
       " '+7 (495) 155 68 46',\n",
       " '+7 916 429-21-81',\n",
       " '8-926-531-38-74']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_phones(text):\n",
    "    phone_pattern = re.compile(\n",
    "        r'''\n",
    "        (?:(?:\\+7|8)[\\s\\-]?)?            # код страны (+7 или 8)\n",
    "        \\(?\\d{3}\\)?[\\s\\-]?               # код города (например, 495)\n",
    "        \\d{3}[\\s\\-]?\\d{2}[\\s\\-]?\\d{2}    # основной номер\n",
    "        (?:\\s*(?:доб\\.?|ext\\.?)\\s*\\d{1,5})? # добавочный, если есть\n",
    "        ''',\n",
    "        re.VERBOSE\n",
    "    )\n",
    "    return [match.group().strip() for match in phone_pattern.finditer(text)]\n",
    "\n",
    "\n",
    "\n",
    "text = '''Кутузовский проспект, д.12\n",
    "\n",
    "From: Геосинтетика.Москва <info@geosintetika.moscow>\n",
    "Sent: Friday, June 17, 2022 1:41 PM\n",
    "To: Стрелков Сергей Анатольевич <strelkov@iss-mos.ru>\n",
    "Subject: Re: фильтр и дренаж\n",
    "\n",
    "\n",
    "добрый день! Куда нужна доставка?\n",
    "17.06.2022 13:21, Стрелков Сергей Анатольевич пишет:\n",
    "Добрый день!\n",
    "\n",
    "Интересует стоимость и возможность поставки около 18 000м2\n",
    "- Системный фильтр, толщиной 1 мм\n",
    "- Дренажный элемент, толщиной 25 мм\n",
    "\n",
    "С уважением,\n",
    "       Стрелков Сергей Анатольевич\n",
    "       Руководитель проекта\n",
    "       ООО \"ФасадПроф\"\n",
    "       +7 (495) 105-97-55\n",
    "       +7-910-480-24-89\n",
    "        e-mail: strelkov@iss-mos.ru<mailto:strelkov@iss-mos.ru>\n",
    ">+7 (495) 155 68 46, доб. 1\n",
    " <tel:+79639488295%20>\n",
    "--\n",
    "\n",
    "[https://s3.amazonaws.com/htmlsig-assets/spacer.gif]\n",
    "\n",
    "info@geosintetika.moscow<mailto:info@geosintetika.moscow> /\n",
    "\n",
    "[https://s3.amazonaws.com/htmlsig-assets/spacer.gif]\n",
    "Геоосинтетика.Москва\n",
    "+7 (495) 155 68 46, +7 916 429-21-81\n",
    "Офис: г. Москва, м. Киевская ул. Погодинская дом 6\n",
    "Склад: Саларьево, Тихоновская улица, 27\n",
    "https://геосинтетика.москва\n",
    "тел.8-926-531-38-74\n",
    "[https://s3.amazonaws.com/htmlsig-assets/spacer.gif]\n",
    "\n",
    "[https://s3.amazonaws.com/htmlsig-assets/spacer.gif]\n",
    "[cid:image001.png@01D88250.93F7E140]<http://геосинтетика.москва/>\n",
    "\n",
    "[https://s3.amazonaws.com/htmlsig-assets/spacer.gif]'''\n",
    "\n",
    "\n",
    "extract_phones(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f3c87a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
